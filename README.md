ğŸš€ Fake News Detection with TF-IDF, Random Forest, and Sentiment Analysis
This project builds a Fake News Classifier using TF-IDF, Random Forest, and explores additional text analysis techniques like sentiment scoring, word clouds, and model comparisons.

ğŸ“š Project Overview
âœ… Load and clean a dataset of real and fake news articles

âœ‚ï¸ Preprocess text: lowercasing, removing stopwords, lemmatization

ğŸ”  Transform articles into TF-IDF feature vectors

ğŸŒ³ Train a Random Forest model to classify fake vs. real news

ğŸ“ˆ Evaluate model performance with confusion matrix and classification report

ğŸ“ Clean and predict on a new set of validation articles

ğŸ“Š Visualize most common words and word clouds

ğŸ˜ Analyze sentiment distribution across real and fake news

âš¡ Compare different models (Random Forest, Logistic Regression, Naive Bayes)

ğŸ’¾ Save final models and vectorizers for future use

ğŸ› ï¸ Tech Stack

Component	Tool/Library
Text Processing	NLTK, re, WordNetLemmatizer
Feature Extraction	TF-IDF (sklearn)
Classification Models	Random Forest, Logistic Regression, Naive Bayes
Visualization	matplotlib, seaborn, wordcloud
Sentiment Analysis	NLTK Vader
Model Saving	joblib
Environment	Jupyter / Colab
ğŸ§ª How It Works
ğŸ“‚ Load the news dataset (data.csv) and validation set (validation_data.csv)

ğŸ§¹ Clean and preprocess text data for better model focus

ğŸ”  Convert text into TF-IDF vectors

ğŸŒ³ Train a Random Forest model on the training set

ğŸ“ˆ Evaluate with accuracy, precision, recall, and F1-score

ğŸ”® Predict labels for new unseen articles

ğŸ“Š Generate word clouds and sentiment histograms for deeper analysis

ğŸ† Compare Random Forest, Logistic Regression, and Naive Bayes models

ğŸ’» Notebook Contents
Fake_News_Classification.ipynb

 Data loading and cleaning

 TF-IDF feature engineering

 Random Forest model training

 Model evaluation and visualization

 Validation set prediction

 Word frequency analysis

 Sentiment distribution plotting

 Model benchmarking

 Saving models

ğŸ§  Sample Results

Model	Accuracy
Random Forest	~96%
Logistic Regression	~95%
Naive Bayes	~94%
ğŸ¯ TF-IDF + Random Forest achieved the best accuracy.

ğŸ“° Real News had slightly more positive sentiment compared to Fake News.

âš ï¸ Known Issues / Limitations
âŒ Classifier can struggle on very short or ambiguous news texts

ğŸ” TF-IDF doesn't capture deep semantic meaning (consider embeddings for future improvements)

âš¡ Some overlap between dramatic real news and fake news can confuse the classifier

ğŸ“ˆ Improvements & Next Steps
ğŸ” Try deep learning approaches like BERT fine-tuning

ğŸ§  Incorporate more metadata (publication date, source)

ğŸ·ï¸ Perform Named Entity Recognition (NER) to identify suspicious claims

ğŸ§ª Add automated evaluation on external fake news datasets

ğŸš€ Try It Yourself
Make sure to install required libraries first:

bash
Copy
Edit
pip install nltk scikit-learn matplotlib seaborn wordcloud joblib
Download NLTK resources (run once):

python
Copy
Edit
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('vader_lexicon')
Then simply run the notebook!

âœ… DONE!
Would you also want me to give you a bonus tip:
ğŸ”¹ a suggested folder structure (/models, /data, /notebooks, etc.)?
ğŸ”¹ a .gitignore file (e.g., to ignore .pkl model files)?

Tell me if you want â€” ready whenever you are! ğŸš€âœ¨










# Data sets can be found here
https://drive.google.com/drive/folders/1oG1aPaNebt5dIrYEzA8rvsy2TJ2W4NLB?usp=sharing
